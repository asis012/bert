{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:metal]",
      "language": "python",
      "name": "conda-env-metal-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Copy of Basics.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asis012/bert/blob/master/Basics_snorkel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDXucuOHXQs4",
        "colab_type": "text"
      },
      "source": [
        "# Basics Tutorial for Snorkel MeTaL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAbiY8cfXQs8",
        "colab_type": "text"
      },
      "source": [
        "The purpose of this tutorial is to introduce the basic pipeline, classes, and debugging/analysis tools in Snorkel MeTaL. In this notebook, we'll investigate a single-task problem with synthetic data, with an emphasis on the basic design concepts of MeTaL. Check out the `tutorials/` directory to see how this basic pipeline extends to the full _multi-task_ setting, and other topics.\n",
        "\n",
        "This tutorial consists of four steps, following the basic [data programming](https://arxiv.org/abs/1605.07723) pipeline as in [Snorkel](https://hazyresearch.github.io/snorkel/):\n",
        "1. **Load Data:** In the _weakly supervised_ setting, we only have access to unlabeled data points `X`, matrix of noisy labels `L`, and dev/test labels `Y`*\n",
        "2. **Train Label Model:** The purpose of the `LabelModel` is to estimate the unknown accuracies of the labeling functions, _without access to `Y`_, and then use this to denoise and combine them into a set of _probabilistic training labels_.\n",
        "3. **Train End Model:** We can then use these training labels to supervise a discriminative classifier!\n",
        "4. **Evaluate:** We evaluate this model on a held-out test set\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqV0itAKX9YX",
        "colab_type": "code",
        "outputId": "bf456788-32a4-452c-b918-1fee694f31c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        }
      },
      "source": [
        "!pip install metal"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting metal\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/57/cbc7fe78e9b98c365e17aacda0d079bc05575d7a4d698f20641fd948606d/metal-0.1.7.tar.gz (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from metal) (1.9.189)\n",
            "Collecting pyaws>=0.1.18 (from metal)\n",
            "  Downloading https://files.pythonhosted.org/packages/91/97/00212a996f39364394938696dacd865641d7a2ce49b5a5f4861efacee3cc/pyaws-0.2.33.tar.gz\n",
            "Requirement already satisfied: Pygments in /usr/local/lib/python3.6/dist-packages (from metal) (2.1.3)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->metal) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->metal) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.189 in /usr/local/lib/python3.6/dist-packages (from boto3->metal) (1.12.189)\n",
            "Collecting awscli>=1.16.100boto3>=1.9.100 (from pyaws>=0.1.18->metal)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/82/99ed4bfad39ace624a5a547b96e520b8f61a01348758c277f0a79aeeb315/awscli-1.16.209-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.189->boto3->metal) (2.5.3)\n",
            "Requirement already satisfied: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.189->boto3->metal) (1.24.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.189->boto3->metal) (0.14)\n",
            "Requirement already satisfied: PyYAML<=5.1,>=3.10; python_version != \"2.6\" in /usr/local/lib/python3.6/dist-packages (from awscli>=1.16.100boto3>=1.9.100->pyaws>=0.1.18->metal) (3.13)\n",
            "Collecting rsa<=3.5.0,>=3.1.2 (from awscli>=1.16.100boto3>=1.9.100->pyaws>=0.1.18->metal)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/ae/baedc9cb175552e95f3395c43055a6a5e125ae4d48a1d7a924baca83e92e/rsa-3.4.2-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 22.8MB/s \n",
            "\u001b[?25hCollecting colorama<=0.3.9,>=0.2.5 (from awscli>=1.16.100boto3>=1.9.100->pyaws>=0.1.18->metal)\n",
            "  Downloading https://files.pythonhosted.org/packages/db/c8/7dcf9dbcb22429512708fe3a547f8b6101c0d02137acbd892505aee57adf/colorama-0.3.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.189->boto3->metal) (1.12.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<=3.5.0,>=3.1.2->awscli>=1.16.100boto3>=1.9.100->pyaws>=0.1.18->metal) (0.4.5)\n",
            "Building wheels for collected packages: metal, pyaws\n",
            "  Building wheel for metal (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for metal: filename=metal-0.1.7-cp36-none-any.whl size=37567 sha256=9f0a7d108bb18d6322e74f5baa622de526b806c32ea92309a00c306a023a35bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/c9/16/465b63d77648d0ccba3b6343ae82849b5f123151341f0f7687\n",
            "  Building wheel for pyaws (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyaws: filename=pyaws-0.2.33-cp36-none-any.whl size=54153 sha256=a33998062ea54f2cd6e2ef2c3cf958b28d68c3ffc3571c7e33f9b5cc081739cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/6a/26/6f32da74d4be696d29a965f23ba1b6315ced1bde11d8b35de8\n",
            "Successfully built metal pyaws\n",
            "\u001b[31mERROR: awscli 1.16.209 has requirement botocore==1.12.199, but you'll have botocore 1.12.189 which is incompatible.\u001b[0m\n",
            "Installing collected packages: rsa, colorama, awscli, pyaws, metal\n",
            "  Found existing installation: rsa 4.0\n",
            "    Uninstalling rsa-4.0:\n",
            "      Successfully uninstalled rsa-4.0\n",
            "Successfully installed awscli-1.16.209 colorama-0.3.9 metal-0.1.7 pyaws-0.2.33 rsa-3.4.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "rsa"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXYgC246iR29",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "26cd8959-de98-4d6f-9343-4e00c6b167ea"
      },
      "source": [
        "\n",
        "!pip install git+https://github.com/HazyResearch/metal"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/HazyResearch/metal\n",
            "  Cloning https://github.com/HazyResearch/metal to /tmp/pip-req-build-r2qw1fj7\n",
            "  Running command git clone -q https://github.com/HazyResearch/metal /tmp/pip-req-build-r2qw1fj7\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from snorkel-metal==0.5.0) (0.3.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.6/dist-packages (from snorkel-metal==0.5.0) (2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from snorkel-metal==0.5.0) (1.16.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from snorkel-metal==0.5.0) (0.24.2)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.6/dist-packages (from snorkel-metal==0.5.0) (1.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from snorkel-metal==0.5.0) (1.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from snorkel-metal==0.5.0) (4.28.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from snorkel-metal==0.5.0) (0.21.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.2->snorkel-metal==0.5.0) (4.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->snorkel-metal==0.5.0) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->snorkel-metal==0.5.0) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->snorkel-metal==0.5.0) (0.13.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas->snorkel-metal==0.5.0) (1.12.0)\n",
            "Building wheels for collected packages: snorkel-metal\n",
            "  Building wheel for snorkel-metal (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for snorkel-metal: filename=snorkel_metal-0.5.0-cp36-none-any.whl size=6482113 sha256=842068d47e7f04fe3cd583a7a3fce23afb725560619bd889ba56fbfc36321b2f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rg77kc6g/wheels/76/4e/05/2004ecfdd9320a5f0d0fa9288ab697939c388517a6df30f33d\n",
            "Successfully built snorkel-metal\n",
            "Installing collected packages: snorkel-metal\n",
            "Successfully installed snorkel-metal-0.5.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "metal"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwxRxkP1jq7F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "fa7aa256-a73a-458d-e3cd-b2b24c2e19dc"
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/12/dcaf67e1312475b26db9e45e7bb6f32b540671a9ee120b3a72d9e09bc517/tensorboardX-1.8-py2.py3-none-any.whl (216kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 14.5MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 3.3MB/s eta 0:00:01\r\u001b[K     |████▌                           | 30kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 61kB 4.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 81kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 102kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 112kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 122kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 133kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 143kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 153kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 163kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 174kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 184kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 194kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 204kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 215kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 225kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.16.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX) (41.0.1)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-1.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM5mX44XXQs-",
        "colab_type": "text"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVMzCRVbXQs_",
        "colab_type": "text"
      },
      "source": [
        "We first need to make sure that the `metal/` directory is on our Python path. If the following cell runs without an error, you're all set. If not, make sure that you've installed `snorkel-metal` with pip (conda coming soon) or that you've added the repo to your path if you're running from source; for example, running `source add_to_path.sh` from the repository root."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq2-tjxLXQtB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('../../metal')\n",
        "import metal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UGd9tHZXQtH",
        "colab_type": "code",
        "outputId": "3fe109d9-4bb7-42ab-c8b7-9376410143db",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUmL1MqhXQtN",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyqLnK97XQtO",
        "colab_type": "text"
      },
      "source": [
        "The first step in a Snorkel MeTaL application is preparing your data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjtM3q9pXQtP",
        "colab_type": "text"
      },
      "source": [
        "### Concept 1: Required Data Types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8p0DeH9aR02",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ef551141-24c6-40b6-ddeb-2476c44142b0"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0c429166-8398-4cd4-98f1-09dc78ae6317\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-0c429166-8398-4cd4-98f1-09dc78ae6317\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving basics_tutorial.pkl to basics_tutorial.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU_5wWrHXQtP",
        "colab_type": "text"
      },
      "source": [
        "In particular, MeTaL makes use of the following types of data (n = # examples, m = # labeling functions):\n",
        "* X: an \\[n\\]-dim iterable of end model inputs (e.g., feature vectors or encoded sentences for an RNN)\n",
        "* Y: an \\[n\\]-dim numpy.ndarray of target labels ($Y \\in \\{1,...,k\\}^n$)\n",
        "* L: an \\[n,m\\] scipy.sparse matrix of noisy labels ($L \\in \\{0,...,k\\}^{n \\times m}$, with label 0 reserved for abstentions\n",
        "\n",
        "And optionally (for use with some debugging/analysis tools):\n",
        "* D: an \\[n\\]-dim iterable of human-readable examples (e.g., sentences)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcG-93QXXQtR",
        "colab_type": "text"
      },
      "source": [
        "In this tutorial, we use pre-generated synthetic data, where each example is a bag of words drawn from a different gaussian distribution for each class from a 1000-word vocabulary, and our features are simply the 1000-dimensional vector of counts for each word. For some excellent resources on how to write labeling functions, see the Snorkel tutorials at https://github.com/HazyResearch/snorkel/tree/master/tutorials."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr0YUYdcXQtS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"basics_tutorial.pkl\", 'rb') as f:\n",
        "    X, Y, L, D = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-OAynneXQtX",
        "colab_type": "code",
        "outputId": "1ad163e0-0b1f-4df0-80a3-872ec1f77e4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "print(L.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 1000])\n",
            "(10000,)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAmw9zKmXQtb",
        "colab_type": "text"
      },
      "source": [
        "If you need to divide your data into splits, you can do so with the provided utility function. We split our data 80/10/10 into train/dev/test, stratifying by the labels in `Y` to ensure a similar class balance in each split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDihwXjvXQtc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e46be392-fe2e-4e8e-ced3-8e3acd99f8df"
      },
      "source": [
        "from metal.utils import split_data\n",
        "\n",
        "Xs, Ys, Ls, Ds = split_data(X, Y, L, D, splits=[0.8, 0.1, 0.1], stratify_by=Y, seed=123)\n",
        "\n",
        "print(Ls[1])\n",
        "print(Ys[1])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 0)\t2\n",
            "  (0, 3)\t1\n",
            "  (0, 4)\t1\n",
            "  (0, 5)\t1\n",
            "  (0, 6)\t1\n",
            "  (0, 7)\t2\n",
            "  (0, 8)\t2\n",
            "  (0, 9)\t2\n",
            "  (1, 0)\t2\n",
            "  (1, 3)\t2\n",
            "  (1, 4)\t1\n",
            "  (1, 6)\t1\n",
            "  (1, 8)\t2\n",
            "  (1, 9)\t2\n",
            "  (2, 0)\t2\n",
            "  (2, 1)\t1\n",
            "  (2, 2)\t2\n",
            "  (2, 3)\t2\n",
            "  (2, 4)\t2\n",
            "  (2, 5)\t1\n",
            "  (2, 6)\t1\n",
            "  (2, 7)\t2\n",
            "  (2, 8)\t2\n",
            "  (2, 9)\t2\n",
            "  (3, 0)\t1\n",
            "  :\t:\n",
            "  (997, 0)\t2\n",
            "  (997, 1)\t2\n",
            "  (997, 2)\t2\n",
            "  (997, 3)\t1\n",
            "  (997, 4)\t1\n",
            "  (997, 5)\t1\n",
            "  (997, 6)\t1\n",
            "  (997, 9)\t1\n",
            "  (998, 0)\t2\n",
            "  (998, 1)\t1\n",
            "  (998, 2)\t1\n",
            "  (998, 3)\t1\n",
            "  (998, 4)\t2\n",
            "  (998, 5)\t2\n",
            "  (998, 6)\t1\n",
            "  (998, 7)\t1\n",
            "  (998, 8)\t1\n",
            "  (998, 9)\t2\n",
            "  (999, 0)\t1\n",
            "  (999, 2)\t1\n",
            "  (999, 3)\t1\n",
            "  (999, 4)\t2\n",
            "  (999, 5)\t2\n",
            "  (999, 8)\t1\n",
            "  (999, 9)\t1\n",
            "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRtK42jxXQtf",
        "colab_type": "text"
      },
      "source": [
        "### Investigate Label Matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rmAayrWq07e",
        "colab_type": "text"
      },
      "source": [
        "asdfghjk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3eDO-h5XQtg",
        "colab_type": "text"
      },
      "source": [
        "MeTaL comes with a number of analysis tools for investigating your label matrix. \n",
        "For example, you can view summary statistics for each labeling function.\n",
        "If you have a dev set with gold labels, you can view the empirical accuracy of your functions, in addition to the core summary statistics. If you do not have a dev set with gold labels, simply do not specify optional argument Y.\n",
        "\n",
        "Polarity is a list of classes that a labeling function (LF) predicts for one or more examples. Coverage is the fraction of examples that the labeling function predicts over (as opposed to labeling 0 to abstain). Overlaps is the fraction of examples that the labeling function predicts over that at least one other LF predicts over as well. Conflicts is the fraction of examples that the LF predicts as one class but at least one other LF predicts that same example as a different class. Correct, Incorrect, and Empirical Accuracy are all comparisons to the gold standard labels and thus omitted if Y is not specified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "OJ5wmDstXQth",
        "colab_type": "code",
        "outputId": "b244bf23-5299-4577-b270-a651c60592ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "from metal.analysis import lf_summary\n",
        "\n",
        "lf_summary(Ls[1],Y=Ys[1])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Polarity</th>\n",
              "      <th>Coverage</th>\n",
              "      <th>Overlaps</th>\n",
              "      <th>Conflicts</th>\n",
              "      <th>Correct</th>\n",
              "      <th>Incorrect</th>\n",
              "      <th>Emp. Acc.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[1, 2]</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.655</td>\n",
              "      <td>374</td>\n",
              "      <td>326</td>\n",
              "      <td>0.534286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[1, 2]</td>\n",
              "      <td>0.735</td>\n",
              "      <td>0.735</td>\n",
              "      <td>0.700</td>\n",
              "      <td>468</td>\n",
              "      <td>267</td>\n",
              "      <td>0.636735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[1, 2]</td>\n",
              "      <td>0.744</td>\n",
              "      <td>0.744</td>\n",
              "      <td>0.701</td>\n",
              "      <td>500</td>\n",
              "      <td>244</td>\n",
              "      <td>0.672043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[1, 2]</td>\n",
              "      <td>0.748</td>\n",
              "      <td>0.748</td>\n",
              "      <td>0.706</td>\n",
              "      <td>540</td>\n",
              "      <td>208</td>\n",
              "      <td>0.721925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[1, 2]</td>\n",
              "      <td>0.719</td>\n",
              "      <td>0.719</td>\n",
              "      <td>0.675</td>\n",
              "      <td>454</td>\n",
              "      <td>265</td>\n",
              "      <td>0.631433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[1, 2]</td>\n",
              "      <td>0.746</td>\n",
              "      <td>0.746</td>\n",
              "      <td>0.696</td>\n",
              "      <td>457</td>\n",
              "      <td>289</td>\n",
              "      <td>0.612601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[1, 2]</td>\n",
              "      <td>0.762</td>\n",
              "      <td>0.762</td>\n",
              "      <td>0.728</td>\n",
              "      <td>509</td>\n",
              "      <td>253</td>\n",
              "      <td>0.667979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[1, 2]</td>\n",
              "      <td>0.796</td>\n",
              "      <td>0.796</td>\n",
              "      <td>0.744</td>\n",
              "      <td>593</td>\n",
              "      <td>203</td>\n",
              "      <td>0.744975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[1, 2]</td>\n",
              "      <td>0.811</td>\n",
              "      <td>0.811</td>\n",
              "      <td>0.756</td>\n",
              "      <td>642</td>\n",
              "      <td>169</td>\n",
              "      <td>0.791615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[1, 2]</td>\n",
              "      <td>0.784</td>\n",
              "      <td>0.784</td>\n",
              "      <td>0.735</td>\n",
              "      <td>559</td>\n",
              "      <td>225</td>\n",
              "      <td>0.713010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Polarity  Coverage  Overlaps  Conflicts  Correct  Incorrect  Emp. Acc.\n",
              "0   [1, 2]     0.700     0.700      0.655      374        326   0.534286\n",
              "1   [1, 2]     0.735     0.735      0.700      468        267   0.636735\n",
              "2   [1, 2]     0.744     0.744      0.701      500        244   0.672043\n",
              "3   [1, 2]     0.748     0.748      0.706      540        208   0.721925\n",
              "4   [1, 2]     0.719     0.719      0.675      454        265   0.631433\n",
              "5   [1, 2]     0.746     0.746      0.696      457        289   0.612601\n",
              "6   [1, 2]     0.762     0.762      0.728      509        253   0.667979\n",
              "7   [1, 2]     0.796     0.796      0.744      593        203   0.744975\n",
              "8   [1, 2]     0.811     0.811      0.756      642        169   0.791615\n",
              "9   [1, 2]     0.784     0.784      0.735      559        225   0.713010"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tgA0ygBrszx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3BaTfi_XQtm",
        "colab_type": "text"
      },
      "source": [
        "If you're interested in more graphical investigative tools, you can take a look at the Visualization tutorial.  \n",
        "Once you're satisfied with your label matrices, it's time to aggregate the labels using the label model and train an end model with the resulting probabilistic labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xOTduupXQtn",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Train Label Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rifJgNNXQto",
        "colab_type": "text"
      },
      "source": [
        "### Concept: Config dicts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_n_aKX4XQtp",
        "colab_type": "text"
      },
      "source": [
        "All Snorkel MeTaL models are driven by configuration dictionaries, or config dicts; that is, all settings for running the given model are stored in a single dictionary, `self.config`. \n",
        "\n",
        "When a model is initialized or the train_model() method is called, any extra keyword arguments passed by the user will be used to update the config dict. Then, throughout the class's methods, whenever a setting needs to be looked up, it is pulled from this dictionary, rather than required as a keyword. This has a number of benefits:\n",
        "\n",
        "1. Default values are stored in only one place, the default config dict, rather than in multiple method signatures.\n",
        "1. Code maintenance is simplified, since fewer keyword arguments need to be passed up and down the call stack.\n",
        "2. Logging is simplified, since the complete settings for a given model can be logged by simply writing the config dict (a python dictionary) to file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LpQjYgkXQtq",
        "colab_type": "text"
      },
      "source": [
        "### Label Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5_waC-lXQtr",
        "colab_type": "text"
      },
      "source": [
        "When constructing a LabelModel, the only required argument is `k`, the cardinality of the task. For example, k=2 means a binary classification task where 1 and 2 are the class labels, and 0 is reserved for an abstain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T1on9DnXQtu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from metal.label_model import LabelModel\n",
        "label_model = LabelModel(k=2, seed=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2mqFNoGXQtw",
        "colab_type": "text"
      },
      "source": [
        "The only required argument to `LabelModel.train_model()` is a label matrix. All other keyword arguments are optional. \n",
        "\n",
        "For example, if you know the class_balance of your data, you can pass that in as a list or array; alternatively, you may pass in the target labels of your dev set (`Y_dev`) and have the class balance estimated from that. If neither of these is provided, the classes are assumed to be uniformly distributed.\n",
        "\n",
        "Any other keyword arguments (e.g., the number of epochs (`n_epochs`), logging frequency (`log_train_every`), learning rate (`lr`), L2 regularization (`l2`), optimizer type (`optimizer`), etc.) will be used to update the config dict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqrm7MWjXQtx",
        "colab_type": "code",
        "outputId": "2840fad9-7ea3-401a-d871-717b25139244",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "label_model.train_model(Ls[0], Y_dev=Ys[1], n_epochs=500, log_train_every=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing O...\n",
            "Estimating \\mu...\n",
            "[50 epo]: TRAIN:[loss=0.039]\n",
            "[100 epo]: TRAIN:[loss=0.003]\n",
            "[150 epo]: TRAIN:[loss=0.002]\n",
            "[200 epo]: TRAIN:[loss=0.002]\n",
            "[250 epo]: TRAIN:[loss=0.002]\n",
            "[300 epo]: TRAIN:[loss=0.002]\n",
            "[350 epo]: TRAIN:[loss=0.002]\n",
            "[400 epo]: TRAIN:[loss=0.002]\n",
            "[450 epo]: TRAIN:[loss=0.002]\n",
            "[500 epo]: TRAIN:[loss=0.002]\n",
            "Finished Training\n",
            "CPU times: user 993 ms, sys: 51.8 ms, total: 1.05 s\n",
            "Wall time: 516 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRJYWRBwXQt2",
        "colab_type": "text"
      },
      "source": [
        "You can test the quality of our label model on our dev set as a sanity check, but we'll see if we can do better in Step 3 by using the predictions of the label model to train a discriminative model over a larger feature set than just the outputs of these ten labeling functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktE8SJ5SXQt3",
        "colab_type": "code",
        "outputId": "a18a2945-5c17-41f1-fa44-cedaf47615c5",
        "colab": {}
      },
      "source": [
        "score = label_model.score((Ls[1], Ys[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.879\n",
            "        y=1    y=2   \n",
            " l=1    181    65    \n",
            " l=2    56     698   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krYZk50jXQt7",
        "colab_type": "text"
      },
      "source": [
        "We can see that our trained `LabelModel` outperforms the baseline of taking the majority vote label by approximately 4 accuracy points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfWRB56VXQt8",
        "colab_type": "code",
        "outputId": "903bc8d9-7a02-464d-bfa2-0b840b0320b4",
        "colab": {}
      },
      "source": [
        "print('Trained Label Model Metrics:')\n",
        "scores = label_model.score((Ls[1], Ys[1]), metric=['accuracy','precision', 'recall', 'f1'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trained Label Model Metrics:\n",
            "Accuracy: 0.879\n",
            "Precision: 0.764\n",
            "Recall: 0.736\n",
            "F1: 0.749\n",
            "        y=1    y=2   \n",
            " l=1    181    65    \n",
            " l=2    56     698   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBrSk2D7XQt_",
        "colab_type": "code",
        "outputId": "de7bca5c-c0b4-4121-c4df-ff9b954addb2",
        "colab": {}
      },
      "source": [
        "from metal.label_model.baselines import MajorityLabelVoter\n",
        "\n",
        "mv = MajorityLabelVoter(seed=123)\n",
        "print('Majority Label Voter Metrics:')\n",
        "scores = mv.score((Ls[1], Ys[1]), metric=['accuracy','precision', 'recall', 'f1'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Majority Label Voter Metrics:\n",
            "Accuracy: 0.836\n",
            "Precision: 0.623\n",
            "Recall: 0.841\n",
            "F1: 0.716\n",
            "        y=1    y=2   \n",
            " l=1    207    39    \n",
            " l=2    125    629   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "by4t9Kj5XQuB",
        "colab_type": "text"
      },
      "source": [
        "We can see that our trained `LabelModel` outperforms the baseline of taking the majority vote label by approximately 0.04 in accuracy and 0.03 in F1 on the dev set. However, it has lower recall. Which of these metrics matters most will vary by application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb-GTx7TXQuC",
        "colab_type": "text"
      },
      "source": [
        "### Concept: Classifier Base Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhdX-EUMXQuD",
        "colab_type": "text"
      },
      "source": [
        "Both the `LabelModel` and `EndModel` in MeTaL are children of the parent `Classifier` class. The `Classifier` class defines three important methods related to making predictions:\n",
        "* `predict_proba()`: Returns an [n, k+1] numpy array of probabilistic labels (k+1 because of the option to abstain)\n",
        "* `predict()`: Returns an [n]-dim numpy array of  int labels in {0,...,k+1}\n",
        "* `score()`: Returns the score (default: accuracy) of the predictions with respect to target labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0qfU91MXQuE",
        "colab_type": "text"
      },
      "source": [
        "Following the data programming paradigm, we will use our label model's probabilistic (float) predictions as training labels for a discriminative end model. Because we want probabilistic labels, we use the `predict_proba()` method here. The predictions are in the form of an [n,k] np.ndarray of floats summing to 1.0 in each row, where `Y_ps[i,j]` is the predicted probability of the $i$th data point having true label $j$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOn6lx7cXQuG",
        "colab_type": "code",
        "outputId": "f2152305-cb53-48d7-d902-1df88f633aa1",
        "colab": {}
      },
      "source": [
        "# Y_train_ps stands for \"Y[labels]_train[split]_p[redicted]s[oft]\"\n",
        "Y_train_ps = label_model.predict_proba(Ls[0])\n",
        "Y_train_ps"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.33879477, 0.66120523],\n",
              "       [0.01750565, 0.98249435],\n",
              "       [0.02757499, 0.97242501],\n",
              "       ...,\n",
              "       [0.74142135, 0.25857865],\n",
              "       [0.98866597, 0.01133403],\n",
              "       [0.38616857, 0.61383143]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skyHR0RyXQuN",
        "colab_type": "text"
      },
      "source": [
        "### Analysis tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYtYq_e7XQuO",
        "colab_type": "text"
      },
      "source": [
        "At this point, we may want to analyze our LabelModel's predictions so that we better understand what our model is learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo6V32uSXQuP",
        "colab_type": "text"
      },
      "source": [
        "We can take a look at the confusion matrix to get a sense for class size, error rates, and commonly confused classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XVVVcD4XQuR",
        "colab_type": "code",
        "outputId": "88caf9d5-b756-4686-9b0f-87620514f08a",
        "colab": {}
      },
      "source": [
        "from metal.analysis import confusion_matrix\n",
        "\n",
        "Y_dev_p = label_model.predict(Ls[1])\n",
        "\n",
        "cm = confusion_matrix(Ys[1], Y_dev_p)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        y=1    y=2   \n",
            " l=1    181    56    \n",
            " l=2    65     698   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2n28KedXQuX",
        "colab_type": "text"
      },
      "source": [
        "If matplotlib is installed, we can also use some of the visualization tools provided in the `contrib/` directory to plot the label distributions.  \n",
        "First, we observe that our problem has a severe class imbalance, which our classifier captures in a general sense.  \n",
        "Second, we can look at how confident our model is in its predictions for class 1 and see that most have probabilities very close to 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "v729dJgFXQuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dYfKZeuXQub",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Train End Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol5jAVpyXQud",
        "colab_type": "text"
      },
      "source": [
        "We will now construct and train our `EndModel` on the predictions from the LabelModel. Here we describe the construction of a single-task end model. For details on the construction of multi-task end models, refer to the multi-task tutorial.\n",
        "\n",
        "The `EndModel` consists of three components: an *input layer*, zero or more *middle layers*, and a *head layer*, with each layer consisting of a torch.nn.Module followed by various optional additional operators (e.g., a ReLU nonlinearity, batch normalization, and/or dropout). \n",
        "\n",
        "* **Input layer**:\n",
        "The input module is an IdentityModule by default, which simply accepts arbitrary-length feature vectors from X as torch.Tensors and passes them on to the next module in the network. If, however, you would like provide your data in some other format, you may pass in a custom nn.Module which maps your input type to torch.Tensors (for example, if your data points are images, you may pass in a ResNet as your input module).\n",
        "\n",
        "* **Middle layers**\n",
        "The middle layers are layers between the input layer and head layer. Middle modules are nn.Linear by default.\n",
        "\n",
        "* **Head layer**:\n",
        "The head layer is the final layer, consisting of an nn.Linear module (plus a softmax operation when making predictions).\n",
        " \n",
        "When initiated, the EndModel requires a list of output dimensions. \n",
        "The first element is the output dimension of the input module (which is equal to the dimensionality of your feature vectors if using the default Identitymodule).\n",
        "The last element is the cardinality of the classifier.\n",
        "The elements in the middle define the number and dimensionality of any middle layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "YBXfbGtAXQue",
        "colab_type": "code",
        "outputId": "a4c71ecd-698f-4272-8f88-bbe86f1766fc",
        "colab": {}
      },
      "source": [
        "from metal.end_model import EndModel\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    device='cpu'\n",
        "end_model = EndModel([1000,10,2], seed=123, device=device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Network architecture:\n",
            "Sequential(\n",
            "  (0): IdentityModule()\n",
            "  (1): Sequential(\n",
            "    (0): Linear(in_features=1000, out_features=10, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
            ")\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAIA_kLoXQuh",
        "colab_type": "text"
      },
      "source": [
        "Once initiated, the network structure is printed so you can confirm that it captured the architecture you want."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vOV8SPsXQui",
        "colab_type": "text"
      },
      "source": [
        "To train the model, we pass in our unlabeled training data, our predicted probabilistic (float) labels from the label aggregator, a dev set X and Y if we want to checkpoint the best model seen so far as we train, and any other keyword arguments that you'd like to update in the config dict. For this synthetic problem, the trends in our data are fairly simple, so our model will begin to overfit very quickly. If we do begin to overfit and see our dev score go down, however, the best model seen at any epoch will be restored at the end of training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "4uGmMQa8XQuj",
        "colab_type": "code",
        "outputId": "c8bb2375-2c6c-4f05-f286-8a900875bd6f",
        "colab": {}
      },
      "source": [
        "end_model.train_model((Xs[0], Y_train_ps), valid_data=(Xs[1], Ys[1]), lr=0.01, l2=0.01, batch_size=256, \n",
        "                n_epochs=5, checkpoint_metric='accuracy', checkpoint_metric_mode='max')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 epo]: TRAIN:[loss=0.510] VALID:[accuracy=0.935]\n",
            "Saving model at iteration 1 with best score 0.935\n",
            "[2 epo]: TRAIN:[loss=0.477] VALID:[accuracy=0.973]\n",
            "Saving model at iteration 2 with best score 0.973\n",
            "[3 epo]: TRAIN:[loss=0.473] VALID:[accuracy=0.964]\n",
            "[4 epo]: TRAIN:[loss=0.471] VALID:[accuracy=0.973]\n",
            "[5 epo]: TRAIN:[loss=0.469] VALID:[accuracy=0.976]\n",
            "Saving model at iteration 5 with best score 0.976\n",
            "Restoring best model from iteration 5 with score 0.976\n",
            "Finished Training\n",
            "Accuracy: 0.976\n",
            "        y=1    y=2   \n",
            " l=1    222    24    \n",
            " l=2     0     754   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R4VXp52XQuq",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY0JocwyXQur",
        "colab_type": "text"
      },
      "source": [
        "With a trained EndModel, we can now evaluate performance on our held-out test set, observing a substantial boost in F1 score over using the LabelModel directly. Remember that the label model predicts Y from the labeling functions, L, whereas the end model predicts Y from the raw input, X."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "mT2mYo_8XQut",
        "colab_type": "code",
        "outputId": "c2a6bab2-afc5-4b98-d8e2-ee103fe2633f",
        "colab": {}
      },
      "source": [
        "print(\"Label Model:\")\n",
        "score = label_model.score((Ls[2], Ys[2]), metric=['accuracy','precision', 'recall', 'f1'])\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"End Model:\")\n",
        "score = end_model.score((Xs[2], Ys[2]), metric=['accuracy','precision', 'recall', 'f1'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label Model:\n",
            "Accuracy: 0.869\n",
            "Precision: 0.747\n",
            "Recall: 0.707\n",
            "F1: 0.727\n",
            "        y=1    y=2   \n",
            " l=1    174    72    \n",
            " l=2    59     695   \n",
            "\n",
            "End Model:\n",
            "Accuracy: 0.965\n",
            "Precision: 1.000\n",
            "Recall: 0.858\n",
            "F1: 0.923\n",
            "        y=1    y=2   \n",
            " l=1    211    35    \n",
            " l=2     0     754   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpkxHRSIXQuw",
        "colab_type": "text"
      },
      "source": [
        "And there you go! If you'd like to learn about some of the other features in Snorkel MeTaL, including support for multi-task learning (MTL), hyperparameter tuning, and synthetic data generation, give some of the other tutorial notebooks a try!"
      ]
    }
  ]
}